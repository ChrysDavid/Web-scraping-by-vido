# Web Scraper Pro ğŸš€

Interface web professionnelle pour le scraping de sites web et le tÃ©lÃ©chargement de contenus YouTube, dÃ©veloppÃ©e avec Flask.

## âœ¨ FonctionnalitÃ©s

### ğŸŒ Web Scraping
- TÃ©lÃ©chargement complet de sites web (HTML, CSS, JS, images, polices)
- Navigation intelligente entre les pages
- Configuration flexible des options de tÃ©lÃ©chargement
- Respect des robots.txt et limitations de dÃ©bit
- Organisation automatique des fichiers

### ğŸ“¹ YouTube Downloader
- TÃ©lÃ©chargement de vidÃ©os individuelles
- Support des playlists complÃ¨tes
- Choix de la qualitÃ© vidÃ©o
- Extraction audio uniquement (MP3)
- Interface intuitive avec aperÃ§u des vidÃ©os

### ğŸ›ï¸ Interface Web
- Design responsive avec Bootstrap 5
- Suivi en temps rÃ©el des tÃ©lÃ©chargements
- Historique complet des tÃ¢ches
- Gestion des erreurs avancÃ©e
- Interface multilingue (franÃ§ais)

## ğŸ› ï¸ Installation

### PrÃ©requis
- Python 3.8 ou supÃ©rieur
- Google Chrome ou Chromium installÃ©
- Git (pour cloner le projet)

### Installation automatique

```bash
# Cloner le projet
git clone <URL_DU_PROJET>
cd web_scraper_flask

# CrÃ©er un environnement virtuel
python -m venv venv

# Activer l'environnement virtuel
# Sur Windows:
venv\Scripts\activate
# Sur Linux/Mac:
source venv/bin/activate

# Installer les dÃ©pendances
pip install -r requirements.txt

# Lancer l'application
python run.py
```

### Installation manuelle

1. **Cloner le projet**
```bash
git clone <URL_DU_PROJET>
cd web_scraper_flask
```

2. **CrÃ©er l'environnement virtuel**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
```

3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

4. **Configurer l'application**
```bash
# Copier le fichier de configuration
cp config.py.example config.py
# Ã‰diter selon vos besoins
```

5. **Lancer l'application**
```bash
python run.py
```

## ğŸ“ Structure du projet

```
web_scraper_flask/
â”‚
â”œâ”€â”€ app.py                      # Application Flask principale
â”œâ”€â”€ config.py                  # Configuration
â”œâ”€â”€ run.py                     # Script de lancement
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ README.md                  # Documentation
â”‚
â”œâ”€â”€ scrapers/                  # Modules de scraping
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ web_scraper.py        # Scraper web avec Selenium
â”‚   â”œâ”€â”€ youtube_scraper.py    # TÃ©lÃ©chargeur YouTube
â”‚   â””â”€â”€ utils.py              # Utilitaires communs
â”‚
â”œâ”€â”€ templates/                 # Templates HTML
â”‚   â”œâ”€â”€ base.html             # Template de base
â”‚   â”œâ”€â”€ index.html            # Page d'accueil
â”‚   â”œâ”€â”€ web_scraping.html     # Interface web scraping
â”‚   â”œâ”€â”€ youtube.html          # Interface YouTube
â”‚   â””â”€â”€ results.html          # Historique
â”‚
â”œâ”€â”€ static/                   # Fichiers statiques
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css        # Styles personnalisÃ©s
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ main.js          # JavaScript principal
â”‚
â”œâ”€â”€ downloads/                # Dossier des tÃ©lÃ©chargements
â”‚   â”œâ”€â”€ web_content/         # Contenu web
â”‚   â””â”€â”€ youtube_content/     # VidÃ©os YouTube
â”‚
â””â”€â”€ logs/                    # Fichiers de logs
    â””â”€â”€ app.log
```

## ğŸš€ Utilisation

### DÃ©marrage rapide

1. **Lancer l'application**
```bash
python run.py
```

2. **Ouvrir votre navigateur** et aller sur `http://localhost:5000`

3. **Choisir votre mode** :
   - **Web Scraping** : Pour tÃ©lÃ©charger des sites web
   - **YouTube** : Pour tÃ©lÃ©charger des vidÃ©os YouTube

### Web Scraping

1. Entrez l'URL du site Ã  scraper
2. Configurez les options :
   - Nombre maximum de pages
   - Types de fichiers Ã  tÃ©lÃ©charger
   - DÃ©lai entre les requÃªtes
3. Cliquez sur "DÃ©marrer le Scraping"
4. Suivez la progression en temps rÃ©el
5. TÃ©lÃ©chargez le fichier ZIP gÃ©nÃ©rÃ©

### YouTube Downloader

1. Collez l'URL de la vidÃ©o ou playlist YouTube
2. Choisissez les options :
   - QualitÃ© vidÃ©o
   - Audio seulement (MP3)
   - Type de contenu (vidÃ©o/playlist)
3. Cliquez sur "TÃ©lÃ©charger"
4. RÃ©cupÃ©rez vos fichiers

## âš™ï¸ Configuration

Ã‰ditez le fichier `config.py` pour personnaliser :

```python
class Config:
    # Scraping web
    DEFAULT_MAX_PAGES = 10
    DEFAULT_TIMEOUT = 30
    
    # YouTube
    DEFAULT_QUALITY = 'best'
    
    # SÃ©curitÃ©
    ALLOWED_DOMAINS = []  # Vide = tous autorisÃ©s
    BLOCKED_DOMAINS = ['facebook.com', 'instagram.com']
    
    # Limites
    MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB
    MAX_TOTAL_SIZE = 100 * 1024 * 1024  # 100MB
```

## ğŸ”§ API Endpoints

### Routes principales
- `GET /` - Page d'accueil
- `GET /web-scraping` - Interface web scraping
- `GET /youtube-download` - Interface YouTube
- `GET /results` - Historique des tÃ©lÃ©chargements

### API REST
- `POST /start-web-scraping` - DÃ©marre un scraping web
- `POST /start-youtube-download` - DÃ©marre un tÃ©lÃ©chargement YouTube
- `GET /task-status/<task_id>` - Statut d'une tÃ¢che
- `GET /download/<task_id>` - TÃ©lÃ©charge les rÃ©sultats

## ğŸ› DÃ©pannage

### ProblÃ¨mes courants

**Chrome/ChromeDriver non trouvÃ©**
```bash
# Installer Chrome sur Ubuntu/Debian
sudo apt update && sudo apt install google-chrome-stable

# VÃ©rifier l'installation
google-chrome --version
```

**Erreur de permissions**
```bash
# Donner les permissions d'exÃ©cution
chmod +x run.py
```

**Port dÃ©jÃ  utilisÃ©**
```bash
# Utiliser un autre port
export PORT=8080
python run.py
```

### Logs et dÃ©bogage

Les logs sont disponibles dans :
- `logs/app.log` - Logs gÃ©nÃ©raux
- `logs/scraper.log` - Logs de scraping
- Console du navigateur - Erreurs JavaScript

Pour activer le mode debug :
```bash
export FLASK_DEBUG=true
python run.py
```

## ğŸ“‹ TODO / AmÃ©liorations futures

- [ ] Support de l'authentification utilisateur
- [ ] API REST complÃ¨te avec documentation Swagger
- [ ] Support de plus de plateformes (Vimeo, etc.)
- [ ] Planification de tÃ¢ches rÃ©currentes
- [ ] Interface d'administration avancÃ©e
- [ ] Support des proxies
- [ ] Optimisations de performance
- [ ] Tests unitaires complets
- [ ] Docker et dÃ©ploiement en production

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! 

1. Fork le projet
2. CrÃ©ez une branche pour votre fonctionnalitÃ©
3. Committez vos changements
4. Poussez vers la branche
5. Ouvrez une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ“ Support

Pour obtenir de l'aide :
- Ouvrez une issue sur GitHub
- Consultez la documentation
- VÃ©rifiez les logs d'erreur

## ğŸ”¥ FonctionnalitÃ©s avancÃ©es

### Configuration personnalisÃ©e
- CrÃ©ez un fichier `.env` pour vos variables d'environnement
- Personnalisez les headers HTTP
- Configurez les timeouts et retry

### Surveillance systÃ¨me
- Monitoring de l'usage des ressources
- Alertes en cas d'erreur
- Statistiques dÃ©taillÃ©es

### SÃ©curitÃ©
- Validation stricte des URLs
- Sandbox pour l'exÃ©cution des scrapers
- Rate limiting intÃ©grÃ©